{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ddcf7619",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "ddcf7619"
      },
      "source": [
        "# Машинное обучение, часть 1, ШАД\n",
        "## Домашнее задание 3: Логистическая регрессия\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deeb2129",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "deeb2129"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "...  # допиши необходимые импорты\n",
        "\n",
        "sns.set(style=\"whitegrid\", palette=\"Set2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54071102",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "54071102"
      },
      "source": [
        "*Привет!*\n",
        "\n",
        "*Перед тобой увлекательная домашка по линейной регрессии и градиентным методам оптимизации. Надеемся, что тебе она понравится, ты точно найдешь в ней что-то интересное. Конечно, просто не будет, но никто этого и не обещал. В условии оставлены некоторые скрытые подсказки, будет хорошо, если ты сначала постараешься подумать самостоятельно, а затем раскроешь содержимое подсказки. Если у тебя будут вопросы по условию, можешь обратиться с ними в чат. Только очень желательно не делиться в чате фрагментами решения.*\n",
        "\n",
        "*Успехов в решении!*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00568989",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "00568989"
      },
      "source": [
        "---\n",
        "### Задача 1.\n",
        "\n",
        "Найдите оценку параметра $\\theta$ методом максимального правдоподобия по выборке размера $n$ из распределения:\n",
        "* $\\mathrm{Exp}(\\theta)$ &mdash; экспоненциальное, где $\\theta>0$;\n",
        "* $\\mathrm{Pois}(\\theta)$ &mdash; пуассоновское, где $\\theta>0$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73efa862",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "73efa862"
      },
      "source": [
        "---\n",
        "### Задача 2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6261450",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "f6261450"
      },
      "source": [
        "*Для начала посмотрим на простых примерах, как работает логистическая регрессия, и поймем некоторые ее важные свойства.*\n",
        "\n",
        "*Перед выполнением задачи ознакомтесь с ноутбуком по логистической регрессии с занятия.*\n",
        "\n",
        "> Одно из интересных свойств модели логистической регрессии — *при соблюдении её предположений* она дает возможность получать **несмещенные оценки вероятностей** принадлежности объекта к определенному классу, близкие к идеально скалиброванным. Напомним, модель называется идеально скалиброванной в следующем случае. Рассмотрим объект $x$ и соответствующее предсказание вероятности $\\widehat{p}(x)$ для класса 1. Если взять небольшую окрестность объекта $x$, то доля объектов класса 1 в этой окрестности будет приблизительно равна $\\widehat{p}(x)$.  \n",
        "\n",
        "Далее проверим это свойство на конкретных примерах.\n",
        "\n",
        "С помощью кода ниже сгенерируйте данные, состоящие из одного вещественного признака и бинарного таргета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8de0218",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c8de0218"
      },
      "outputs": [],
      "source": [
        "sample_size = 3_000  # Размер выборки\n",
        "\n",
        "# Признаки\n",
        "X = np.random.uniform(low=-4, high=4, size=(sample_size, 1))\n",
        "\n",
        "# Таргет\n",
        "y_mean_true = 1 / (1 + np.exp(1 - 2 * X.ravel()))\n",
        "y = np.random.binomial(n=1, p=y_mean_true)\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.scatter(X, y_mean_true, marker=\".\", s=1, label=\"Реальные вероятности\\n(мы их не знаем)\")\n",
        "plt.scatter(X, y, marker=\"|\", alpha=0.1, label=\"Данные\")\n",
        "plt.xlabel(\"Признак\")\n",
        "plt.ylabel(\"Класс объекта\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319f805b",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "319f805b"
      },
      "source": [
        "Обучите логистическую регрессию, используя реализацию из `sklearn`, при этом свободный коэффициент должен присутствовать в модели. Укажите также `penalty='none'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f81adfd",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "8f81adfd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6c94ae67",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "6c94ae67"
      },
      "source": [
        "Напечатайте оценку коэффициентов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c802ad7a",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c802ad7a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fb675b64",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "fb675b64"
      },
      "source": [
        "Ниже объявлена сетка значений признака. По этой сетке постройте\n",
        "* предсказания классов,\n",
        "* предсказания вероятностей класса 1.\n",
        "\n",
        "Визуализируйте эти предсказания. На график стоит нанести также обучающую выборку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "993e1a06",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "993e1a06"
      },
      "outputs": [],
      "source": [
        "X_grid = np.linspace(-4, 4, 10_000).reshape((-1, 1))\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "269884a1",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "269884a1"
      },
      "source": [
        "Разбейте отрезок $[-4, 4]$ на одинаковые бины длины длины 0.2 и посчитайте в каждом бине долю объектов класса 1. Полученные значения добавьте на график предсказаний вероятностей и сравните эти графики. Проинтерпретируйте полученные результаты.\n",
        "\n",
        "\n",
        "<br/><details>\n",
        "<summary> ➡️ Кликни для показа подсказки </summary>\n",
        "Может помочь <code>np.digitize</code> и метод <code>groupby</code> для таблиц <code>pandas</code>. Рекомендуем посмотреть <a href=\"https://thetahat.ru/courses/python\">обучающие ноутбуки</a> по библиотекам.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34db7e1b",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "34db7e1b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5f5c9a94",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "5f5c9a94"
      },
      "source": [
        "Позволяют ли посчитанные выше значения построить калибровочную кривую? Если да, поясните и постройте ее график. Если нет, поясните разницу, реализуйте самостоятельно калибровочную кривую и постройте ее график.\n",
        "\n",
        "<br/><details>\n",
        "<summary> ➡️ Кликни для показа подсказки </summary>\n",
        "Посмотри на определение калибровочной кривой и на бины.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a805bd8",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "0a805bd8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "337a4cde",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "337a4cde"
      },
      "source": [
        "Повторите проведенное исследование для следующих данных и сравните результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b95661dd",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "b95661dd"
      },
      "outputs": [],
      "source": [
        "# Признаки\n",
        "X = np.random.uniform(low=-4, high=4, size=(sample_size, 1))\n",
        "\n",
        "# Таргет\n",
        "y_mean_true = 1 / (1 + np.exp(-100 * X.ravel()))\n",
        "y = np.random.binomial(n=1, p=y_mean_true)\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.scatter(X, y_mean_true, marker=\".\", s=1, label=\"Реальные вероятности\")\n",
        "plt.scatter(X, y, marker=\"|\", alpha=0.1, label=\"Данные\")\n",
        "plt.xlabel(\"Признак\")\n",
        "plt.ylabel(\"Класс объекта\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6db9136",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "d6db9136"
      },
      "source": [
        "**Выводы:**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d6b4fe9",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "3d6b4fe9"
      },
      "source": [
        "---\n",
        "### Задача 3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6257fdbf",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "6257fdbf"
      },
      "source": [
        "Продолжим исследовать модель логистической регрессии. Сгенерируем данные, состоящие из двух бинарных признаков и бинарного таргета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c320e033",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c320e033"
      },
      "outputs": [],
      "source": [
        "probs = np.random.uniform(size=8)\n",
        "probs /= probs.sum()\n",
        "probs\n",
        "\n",
        "x = np.random.choice(np.arange(8), p=probs, size=10_000)\n",
        "data = pd.DataFrame(\n",
        "    np.unpackbits(np.array(x.reshape(-1, 1), dtype=\">i8\").view(np.uint8), axis=1)[:, -3:],\n",
        "    columns=[\"feature_1\", \"feature_2\", \"target\"],\n",
        ")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818e5b06",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "818e5b06"
      },
      "source": [
        "Особенность таких данных &mdash; конечное число *возможных различных* объектов. В данном случае их всего 4, по количеству всех возможных комбинаций значений признака. Соответственно, любой моделью мы можем сделать только 4 *различных* предсказания. Исследуем, как с этим справляется логистическая регрессия.\n",
        "\n",
        "Сначала для сравнения посчитайте долю класса 1 для каждой категории объектов.\n",
        "\n",
        "*Подсказка:* используйте `pd.pivot_table`. Рекомендуем посмотреть <a href=\"https://thetahat.ru/courses/python\">обучающие ноутбуки</a> по библиотекам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2e5bd7",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "8a2e5bd7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f580711a",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "f580711a"
      },
      "source": [
        "Обучите логистическую регрессию с `penalty='none'` и получите предсказания вероятностей для этих четырех типов объектов. Представьте результаты в таком виде, чтобы их удобно было сравнивать с частотами, посчитанными ранее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a9445d",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "55a9445d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8d0276cd",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "8d0276cd"
      },
      "source": [
        "Почему результаты не совпадают?\n",
        "\n",
        "Для ответа на этот вопрос распишите формулу, которая задает модель логистической регрессии, указав все параметры. Какое предположение о данных при этом делает логистическая регрессия?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39f3fab",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c39f3fab"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fae9d6",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "28fae9d6"
      },
      "source": [
        "Предложите и реализуйте способ модификации модели логистической регрессии так, чтобы она точнее предсказывала частоты, посчитанные ранее.\n",
        "\n",
        "<br/><details>\n",
        "<summary> ➡️ Кликни для показа подсказки </summary>\n",
        "Подумайте, какое преобразование признаков можно было бы сделать.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a33147b",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "1a33147b"
      },
      "source": [
        "Опишите ваше предложение:\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93eab717",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "93eab717"
      },
      "source": [
        "Реализация:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac90fb09",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "ac90fb09"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d3dabbea",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "d3dabbea"
      },
      "source": [
        "**Выводы:**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d35389",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "f5d35389"
      },
      "source": [
        "---\n",
        "### Задача 4.\n",
        "\n",
        "*Не все в жизни ограничивается двумя классами, бывает и многоклассовый случай.*\n",
        "\n",
        "**1.** Пусть $X_1,...,X_n$ &mdash; выборка независимых одинаково распределенных случайных величин из категориального распределения, то есть $\\mathsf{P}_\\theta(X_1 = j) = \\theta_j$ для $j \\in \\{1, ..., k\\}$, причем $\\theta = (\\theta_1, ..., \\theta_k), \\theta_j \\geqslant 0$ и $\\theta_1 + ... + \\theta_k = 1$. Найдите оценку максимального правдоподобия параметра $\\theta$. Является ли она несмещенной оценкой $\\theta$?\n",
        "\n",
        "<br/><details>\n",
        "<summary> ➡️ Кликни для показа подсказки </summary>\n",
        "Посмотрите на пример с лекции для бернуллиевского распределения.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5ab3ca",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "6b5ab3ca"
      },
      "source": [
        "**2.** Рассмотрим модель логистической регрессии для случая многоклассовой классификации. Пусть метка класса принимает значения в $K$-элементном множестве $\\mathscr{Y} = \\{1, ..., K\\}$. Параметры модели $\\theta$ являются матрицей размерности $K \\times d$, где $d$ &mdash; количество признаков.\n",
        "\n",
        "Введем soft-max функцию:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\left( \\frac{e^{z_1}}{\\sum_{i=1}^K e^{z_i}}, \\dots, \\frac{e^{z_K}}{\\sum_{i=1}^K e^{z_i}} \\right).\n",
        "$$\n",
        "\n",
        "Из определения ясно, что $\\sum\\limits_{i=1}^k \\sigma_k(z) = 1$. Название функции связано с тем, что самая большая компонента вектора $z$ будет близка к $1$, а все остальные будут малы, но не равны нулю. Таким образом, происходит сглаженное взятие `argmax`.\n",
        "\n",
        "По аналогии с обычной логистической регрессией рассмотрим выборку объектов $x_1, ...,  x_n$, где $x_i = (x_{i1}, \\dots, x_{id})^T \\in \\mathscr{X}$, и выборку таргетов $Y_1, ...,  Y_n \\in \\mathscr{Y}$\n",
        "\n",
        "Модель логистической регрессии в многоклассовом случае предполагает, что $\\mathsf{P}_{\\theta}(Y_{ik} = k) = \\sigma_k(\\theta x)$.\n",
        "\n",
        "Выполните следующие действия.\n",
        "\n",
        "1. Определите множество моделей $\\mathcal{M}$, соответствующее логистической регрессии.\n",
        "\n",
        "2. Запишите функцию правдоподобия для такой модели.\n",
        "\n",
        "3. Выпишите формулы GD и SGD для максимизации этой функции правдоподобия. В формулу нужно упростить подобно тому, как было показано на занятии."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760ac26e",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "760ac26e"
      },
      "source": [
        "*Логистическую регрессию для многоклассового случая можно применять и другими способами, подробнее мы разберем на следующих занятиях.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21be75bd",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "21be75bd"
      },
      "source": [
        "---\n",
        "### Задача 5.\n",
        "\n",
        "*Устали писать формулы? Самое время что-то закодить!*\n",
        "\n",
        "*Кроме кодинга в задаче есть исследование. Там, где это возможно, вы можете выполнить исследование без реализации и получить за это частичные баллы.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e4a070",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "05e4a070"
      },
      "source": [
        "**1.** Реализуйте логистическую регрессию для двух вариантов поиска оценки параметров:\n",
        "* простой градиентный спуск;\n",
        "* стохастический градиентный спуск с `batch_size` элементами на каждой итерации.\n",
        "\n",
        "Останавливайте итерации при выполнении хотя бы одного из двух условий:\n",
        "* количество итераций превзошло число `max_iter`;\n",
        "* оптимизируемый функционал изменился за итерацию не более чем на `tol`.\n",
        "\n",
        "При выполнении каждой итерации с целью дальнейшего анализа сохраняйте текущее значение оптимизируемого функционала, а также затраченное время на итерацию.  **При реализации класса запрещено пользоваться ИИ-инструментами.**\n",
        "\n",
        "*Замечания.*\n",
        "\n",
        "1. Для чистоты эксперимента время шага внутри цикла нужно замерять от конца предыдущего шага до конца текущего, а не от начала текущего шага. Время измеряйте с помощью `from time import time`.\n",
        "\n",
        "2. Иногда при подсчете сигмоиды и оптимизируемого функционала могут возникать вычислительные ошибки. Для их избежания существуют специальные трюки.\n",
        "    * [How to Evaluate the Logistic Loss and not NaN trying](http://fa.bianp.net/blog/2019/evaluate_logistic/)\n",
        "    * [Exp-normalize trick](https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/)<br>\n",
        "3. Трюки не обязательно реализовывать самостоятельно, можете воспользоваться функциями для них из `numpy` или `scipy`:\n",
        "    * [`numpy.logaddexp`](https://numpy.org/doc/stable/reference/generated/numpy.logaddexp.html);\n",
        "    * [`scipy.special.logsumexp`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.logsumexp.html).\n",
        "4. Обратите внимание, что класс `LogisticRegression` &mdash; наследник класса `BaseEstimator`, это с легкостью позволит использовать наш класс в различных пайплайнах библиотеки `sklearn`.\n",
        "4. Следите за качеством кода, комментируйте логические этапы кода. Несоблюдение этого требования может привести к потере баллов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774aab77",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "774aab77"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "import numpy as np\n",
        "from time import time\n",
        "from typing import Literal\n",
        "from scipy.special import expit, logsumexp\n",
        "\n",
        "\n",
        "class LogisticRegression(BaseEstimator):\n",
        "    \"\"\"Модель логистической регрессии.\n",
        "\n",
        "    Параметры:\n",
        "    method (Literal['gd', 'sgd']): Метод оптимизации ('gd' - градиентный спуск,\n",
        "        'sgd' - стохастический градиентный спуск).\n",
        "    learning_rate (float): Константа скорости обучения, на которую домножаем градиент при обучении\n",
        "    tol (float): Допустимое изменение функционала между итерациями.\n",
        "    max_iter (int): Максимальное число итераций.\n",
        "    batch_size (int): Размер выборки для оценки градиента (используется только при 'sgd').\n",
        "    fit_intercept (bool): Добавлять ли константу в признаки.\n",
        "    save_history (bool): Сохранять ли историю обучения.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        method: Literal[\"gd\", \"sgd\"] = \"gd\",\n",
        "        learning_rate: float = 0.5,\n",
        "        tol: float = 1e-3,\n",
        "        max_iter: int = int(1e4),\n",
        "        batch_size: int = 64,\n",
        "        fit_intercept: bool = True,\n",
        "        save_history: bool = True,\n",
        "    ):\n",
        "        \"\"\"Создает модель и инициализирует параметры.\"\"\"\n",
        "        self.method = method\n",
        "        self.learning_rate = learning_rate\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.batch_size = batch_size\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.save_history = save_history\n",
        "        self.history = []  # История обучения\n",
        "\n",
        "    @staticmethod\n",
        "    def _sigmoid(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Вычисляет сигмоидную функцию.\"\"\"\n",
        "        # Use logaddexp for numerical stability\n",
        "        return expit(x)\n",
        "\n",
        "    def _log_loss(self, X: np.ndarray, Y: np.ndarray, coef: np.ndarray) -> float:\n",
        "        \"\"\"Вычисляет значение логистической функции потерь.\"\"\"\n",
        "        scores = X @ coef\n",
        "        # Use logsumexp for numerical stability\n",
        "        log_likelihood = np.sum(Y * logsumexp(0, scores) - logsumexp(0, scores))\n",
        "        return -log_likelihood / X.shape[0]\n",
        "\n",
        "\n",
        "    def _add_intercept(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Добавляет свободный коэффициент к матрице признаков.\n",
        "\n",
        "        Параметры: X (np.ndarray): Исходная матрица признаков.\n",
        "\n",
        "        Возвращает: np.ndarray: Матрица X с добавленным свободным\n",
        "        коэффициентом.\n",
        "        \"\"\"\n",
        "        X_copy = np.full((X.shape[0], X.shape[1] + 1), fill_value=1.0)\n",
        "        X_copy[:, :-1] = X\n",
        "        return X_copy\n",
        "\n",
        "    def fit(self, X: np.ndarray, Y: np.ndarray) -> \"LogisticRegression\":\n",
        "        \"\"\"Обучает модель логистической регрессии.\n",
        "\n",
        "        Также, в случае self.save_history=True, добавляет в self.history\n",
        "        текущее значение оптимизируемого функционала и затраченное время.\n",
        "\n",
        "        Параметры:\n",
        "        X (np.ndarray): Матрица признаков.\n",
        "        Y (np.ndarray): Вектор истинных меток.\n",
        "\n",
        "        Возвращает:\n",
        "        LogisticRegression: Обученная модель.\n",
        "        \"\"\"\n",
        "        if X.shape[0] != Y.shape[0]:\n",
        "            raise ValueError(\"Количество строк в X и Y должно совпадать\")\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            X_copy = self._add_intercept(X)\n",
        "        else:\n",
        "            X_copy = X.copy()\n",
        "\n",
        "        # Шаг спуска\n",
        "        n_samples, n_features = X_copy.shape\n",
        "        coef = np.zeros(n_features).reshape(-1, 1)\n",
        "        car_sec = time()\n",
        "        prev_loss = np.inf  # Initialize with infinity for the first iteration\n",
        "\n",
        "\n",
        "        if self.method == \"gd\":\n",
        "          # Градиентный спуск\n",
        "\n",
        "          for i in range(self.max_iter):\n",
        "\n",
        "            scores = X_copy @ coef\n",
        "            predictions = self._sigmoid(scores)\n",
        "            grad = X_copy.T @ (predictions - Y.reshape(-1, 1)) / n_samples\n",
        "            new_coef = coef - self.learning_rate * grad\n",
        "            new_loss = self._log_loss(X_copy, Y, new_coef)\n",
        "\n",
        "\n",
        "            if abs(new_loss - prev_loss) < self.tol:\n",
        "              break\n",
        "\n",
        "            coef = new_coef\n",
        "            prev_loss = new_loss\n",
        "            new_sec = time()\n",
        "\n",
        "            if self.save_history:\n",
        "                self.history.append([new_loss, new_sec - car_sec]) # Сохраняем в историю значение текущее значение функционала и время работы шага\n",
        "\n",
        "            car_sec = new_sec\n",
        "\n",
        "\n",
        "        elif self.method == \"sgd\":\n",
        "          # Стохастический градиентный спуск\n",
        "\n",
        "          for i in range(self.max_iter):\n",
        "\n",
        "            sample_indices = np.random.randint(n_samples, size=self.batch_size)\n",
        "            X_sample = X_copy[sample_indices]\n",
        "            Y_sample = Y[sample_indices].reshape(-1, 1)\n",
        "\n",
        "            scores = X_sample @ coef\n",
        "            predictions = self._sigmoid(scores)\n",
        "            grad = X_sample.T @ (predictions - Y_sample) / self.batch_size\n",
        "\n",
        "\n",
        "            new_coef = coef - self.learning_rate * grad\n",
        "            # Recalculate likelihood over the whole dataset for convergence check\n",
        "            new_loss = self._log_loss(X_copy, Y, new_coef)\n",
        "\n",
        "\n",
        "            if abs(new_loss - prev_loss) < self.tol: # Check tolerance after the first iteration\n",
        "              break\n",
        "\n",
        "            coef = new_coef\n",
        "            prev_loss = new_loss\n",
        "            new_sec = time()\n",
        "\n",
        "            if self.save_history:\n",
        "                self.history.append([new_loss, new_sec - car_sec]) # Сохраняем в историю значение текущее значение функционала и время работы шага\n",
        "\n",
        "            car_sec = new_sec\n",
        "\n",
        "\n",
        "        self.coef_ = coef  # Коэффициенты модели\n",
        "        self.intercept_ = coef[0] if self.fit_intercept else 0 # Свободный коэффициент\n",
        "        self.n_iter_ = i + 1 # Число итераций\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Возвращает предсказанные классы.\n",
        "\n",
        "        Параметры: X (np.ndarray): Матрица признаков.\n",
        "\n",
        "        Возвращает: np.ndarray: Предсказанные классы.\n",
        "        \"\"\"\n",
        "        prob_class_1 = self.predict_proba(X)[:, 1]\n",
        "        predictions = (prob_class_1 >= 0.5).astype(int)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Возвращает вероятности классов 0 и 1.\n",
        "\n",
        "        Параметры: X (np.ndarray): Матрица признаков.\n",
        "\n",
        "        Возвращает: np.ndarray: Матрица вероятностей классов (n_samples,\n",
        "        2).\n",
        "        \"\"\"\n",
        "        if self.fit_intercept:\n",
        "            X_copy = self._add_intercept(X)\n",
        "        else:\n",
        "            X_copy = X.copy()\n",
        "\n",
        "        if X_copy.shape[1] != self.coef_.shape[0]:\n",
        "            raise ValueError(\"Число признаков в X не соответствует числу коэффициентов модели\")\n",
        "\n",
        "        prob_class_1 = self._sigmoid(X_copy @ self.coef_)\n",
        "        prob_predictions = np.hstack([1 - prob_class_1, prob_class_1])\n",
        "\n",
        "        return prob_predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "import numpy as np\n",
        "from time import time\n",
        "from typing import Literal\n",
        "from scipy import special\n",
        "\n",
        "\n",
        "class LogisticRegression(BaseEstimator):\n",
        "    \"\"\"Модель логистической регрессии.\n",
        "\n",
        "    Параметры:\n",
        "    method (Literal['gd', 'sgd']): Метод оптимизации ('gd' - градиентный спуск,\n",
        "        'sgd' - стохастический градиентный спуск).\n",
        "    learning_rate (float): Константа скорости обучения, на которую домножаем градиент при обучении\n",
        "    tol (float): Допустимое изменение функционала между итерациями.\n",
        "    max_iter (int): Максимальное число итераций.\n",
        "    batch_size (int): Размер выборки для оценки градиента (используется только при 'sgd').\n",
        "    fit_intercept (bool): Добавлять ли константу в признаки.\n",
        "    save_history (bool): Сохранять ли историю обучения.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        method: Literal[\"gd\", \"sgd\"] = \"gd\",\n",
        "        learning_rate: float = 0.5,\n",
        "        tol: float = 1e-3,\n",
        "        max_iter: int = int(1e4),\n",
        "        batch_size: int = 64,\n",
        "        fit_intercept: bool = True,\n",
        "        save_history: bool = True,\n",
        "    ):\n",
        "        \"\"\"Создает модель и инициализирует параметры.\"\"\"\n",
        "        self.method = method\n",
        "        self.learning_rate = learning_rate\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.batch_size = batch_size\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.save_history = save_history\n",
        "        self.history = []  # История обучения\n",
        "\n",
        "    @staticmethod\n",
        "    def _sigmoid(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Вычисляет сигмоидную функцию.\"\"\"\n",
        "        # Use logaddexp for numerical stability\n",
        "        return special.expit(x)\n",
        "\n",
        "\n",
        "    def _log_sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Вычисляет логарифм сигмоидной функции\"\"\"\n",
        "        # Use logaddexp for numerical stability\n",
        "        return -np.logaddexp(0, -x)\n",
        "\n",
        "    def _add_intercept(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Добавляет свободный коэффициент к матрице признаков.\n",
        "\n",
        "        Параметры: X (np.ndarray): Исходная матрица признаков.\n",
        "\n",
        "        Возвращает: np.ndarray: Матрица X с добавленным свободным\n",
        "        коэффициентом.\n",
        "        \"\"\"\n",
        "        X_copy = np.full((X.shape[0], X.shape[1] + 1), fill_value=1.0)\n",
        "        X_copy[:, :-1] = X\n",
        "        return X_copy\n",
        "\n",
        "    def fit(self, X: np.ndarray, Y: np.ndarray) -> \"LogisticRegression\":\n",
        "        \"\"\"Обучает модель логистической регрессии.\n",
        "\n",
        "        Также, в случае self.save_history=True, добавляет в self.history\n",
        "        текущее значение оптимизируемого функционала и затраченное время.\n",
        "\n",
        "        Параметры:\n",
        "        X (np.ndarray): Матрица признаков.\n",
        "        Y (np.ndarray): Вектор истинных меток.\n",
        "\n",
        "        Возвращает:\n",
        "        LogisticRegression: Обученная модель.\n",
        "        \"\"\"\n",
        "        if X.shape[0] != Y.shape[0]:\n",
        "            raise ValueError(\"Количество строк в X и Y должно совпадать\")\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            X_copy = self._add_intercept(X)\n",
        "        else:\n",
        "            X_copy = X.copy()\n",
        "        Y_copy = Y.reshape(-1, 1) # Ensure Y is a column vector\n",
        "\n",
        "\n",
        "        # Шаг спуска\n",
        "\n",
        "        coef = np.zeros(X_copy.shape[1]).reshape(-1, 1)\n",
        "        car_sec = time()\n",
        "        car_likelyhood = -np.inf  # Initialize with negative infinity for the first iteration\n",
        "\n",
        "        if self.method == \"gd\":\n",
        "          # Градиентный спуск\n",
        "\n",
        "          for _ in range(self.max_iter):\n",
        "\n",
        "            grad = X_copy.T @ (Y_copy - self._sigmoid(X_copy @ coef))\n",
        "            new_coef = coef + self.learning_rate * grad\n",
        "            new_likelyhood = np.sum(Y_copy * self._log_sigmoid(X_copy @ new_coef) + (1-Y_copy)*self._log_sigmoid(- X_copy @ new_coef))\n",
        "\n",
        "\n",
        "            if (_ > 0) and (abs(new_likelyhood - car_likelyhood) < self.tol):\n",
        "              break\n",
        "\n",
        "            coef = new_coef\n",
        "            car_likelyhood = new_likelyhood\n",
        "            new_sec = time()\n",
        "\n",
        "            if self.save_history:\n",
        "                self.history.append([car_likelyhood, new_sec - car_sec]) # Сохраняем в историю значение текущее значение функционала и время работы шага\n",
        "\n",
        "            car_sec = new_sec\n",
        "\n",
        "\n",
        "        elif self.method == \"sgd\":\n",
        "          # Стохастический градиентный спуск\n",
        "\n",
        "          for _ in range(self.max_iter):\n",
        "\n",
        "            sample_indices = np.random.randint(X_copy.shape[0], size=self.batch_size)\n",
        "            X_sample = X_copy[sample_indices]\n",
        "            Y_sample = Y_copy[sample_indices]\n",
        "\n",
        "            grad = X_sample.T @ (Y_sample - self._sigmoid(X_sample @ coef)) # Removed the scaling factor\n",
        "\n",
        "\n",
        "            new_coef = coef + self.learning_rate * grad\n",
        "            # Recalculate likelihood over the whole dataset for convergence check\n",
        "            new_likelyhood = np.sum(Y_copy * self._log_sigmoid(X_copy @ new_coef) + (1-Y_copy)*self._log_sigmoid(- X_copy @ new_coef))\n",
        "\n",
        "\n",
        "            if (_ > 0) and (abs(new_likelyhood - car_likelyhood) < self.tol): # Check tolerance after the first iteration\n",
        "              break\n",
        "\n",
        "            coef = new_coef\n",
        "            car_likelyhood = new_likelyhood\n",
        "            new_sec = time()\n",
        "\n",
        "            if self.save_history:\n",
        "                self.history.append([car_likelyhood, new_sec - car_sec]) # Сохраняем в историю значение текущее значение функционала и время работы шага\n",
        "\n",
        "            car_sec = new_sec\n",
        "\n",
        "\n",
        "        self.coef_ = coef  # Коэффициенты модели\n",
        "        self.intercept_ = coef[0] if self.fit_intercept else 0 # Свободный коэффициент\n",
        "        self.n_iter_ = _ + 1 # Число итераций\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Возвращает предсказанные классы.\n",
        "\n",
        "        Параметры: X (np.ndarray): Матрица признаков.\n",
        "\n",
        "        Возвращает: np.ndarray: Предсказанные классы.\n",
        "        \"\"\"\n",
        "        prob_class_1 = self.predict_proba(X)[:, 1]\n",
        "        predictions = (prob_class_1 >= 0.5).astype(int)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Возвращает вероятности классов 0 и 1.\n",
        "\n",
        "        Параметры: X (np.ndarray): Матрица признаков.\n",
        "\n",
        "        Возвращает: np.ndarray: Матрица вероятностей классов (n_samples,\n",
        "        2).\n",
        "        \"\"\"\n",
        "        if self.fit_intercept:\n",
        "            X_copy = self._add_intercept(X)\n",
        "        else:\n",
        "            X_copy = X.copy()\n",
        "\n",
        "        if X_copy.shape[1] != self.coef_.shape[0]:\n",
        "            raise ValueError(\"Число признаков в X не соответствует числу коэффициентов модели\")\n",
        "\n",
        "        prob_class_1 = self._sigmoid(X_copy @ self.coef_)\n",
        "        prob_predictions = np.hstack([1 - prob_class_1, prob_class_1])\n",
        "\n",
        "        return prob_predictions"
      ],
      "metadata": {
        "id": "9a1xZ2wpMJAs"
      },
      "id": "9a1xZ2wpMJAs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c21f68f9",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c21f68f9"
      },
      "source": [
        "Рассмотрим датасет [Diabetes Health Indicators](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset).\n",
        "\n",
        "**Для данного задания будем рассматривать версию датасета** `diabetes_binary_5050split_health_indicators_BRFSS2015.csv`\n",
        "\n",
        "\n",
        "Этот датасет содержит статистику здравоохранения и информацию об образе жизни, полученную в результате опросов вместе с меткой наличия/отсутствия диабета у участников. Среди признаков есть демографические данные, результаты лабораторных тестов и ответы на вопросы анкеты. Целевая переменная  `Diabetes_binary` определяет статус пациента: есть ли у него диабет или предиабет (`1`), или он здоров (`0`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e835b3ab",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "e835b3ab"
      },
      "source": [
        "Рассмотрим некоторые признаки, представленные в датасете.\n",
        "\n",
        "**Показатели здоровья**\n",
        "\n",
        "- `HighBP`: Высокое кровяное давление (`1` = да, `0` = нет).\n",
        "\n",
        "- `HighChol`: Высокий уровень холестерина (`1` = да, `0` = нет).\n",
        "\n",
        "- `CholCheck`: Проверка уровня холестерина за последние 5 лет (`1` = да, `0` = нет).\n",
        "\n",
        "- `BMI`: Индекс массы тела (рассчитывается как вес (кг) / рост² (м²)).\n",
        "\n",
        "- `GenHlth`: Общая оценка здоровья (`1` = отличное, `2` = очень хорошее, ..., `5` = плохое).\n",
        "\n",
        "**Образ жизни**\n",
        "- `Smoker`: Статус курения (`1` = выкурил ≥100 сигарет за жизнь, `0` = нет).\n",
        "\n",
        "- `PhysActivity`: Физическая активность вне работы (`1` = да, `0` = нет).\n",
        "\n",
        "- `Fruits`: Регулярное употребление фруктов (`1` = не менее 1 раз в день, `0` = реже).\n",
        "\n",
        "**Доступ к медицине**\n",
        "- `AnyHealthcare`: Наличие медицинской страховки (`1` = да, `0` = нет).\n",
        "\n",
        "- `NoDocbcCost`: Отказ от визита к врачу из-за стоимости (`1` = да, `0` = нет).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e155afaa",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "e155afaa"
      },
      "source": [
        "Скачайте файл и прочитайте его с помощью `pandas`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4a31e1",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "7a4a31e1"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"diabets_health_indicators.csv\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b15a437",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "6b15a437"
      },
      "source": [
        "Разделите выборку на обучающую и тестовую и выполните преобразование категориальных признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffc3926",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "bffc3926"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4d09474e",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "4d09474e"
      },
      "source": [
        "Для интерпретации коэффициентов необходимо нормализовать данные. Воспользуемся для этого классом `StandardScaler` из библиотеки `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926437c3",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "926437c3"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f9f4a6",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "21f9f4a6"
      },
      "source": [
        "**2.** Обучите две модели логистической регрессии с помощью методов\n",
        "* простой градиентный спуск;\n",
        "* стохастический градиентный спуск."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee1a062",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "9ee1a062"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6b64b3cc",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "6b64b3cc"
      },
      "source": [
        "Постройте график, на котором нанесите две кривые обучения, каждая из которых отображает зависимость оптимизируемого функционала от номера итерации метода. **Функционал должен быть одинаковый для всех моделей**. Нарисуйте также график зависимости этого функционала от времени работы метода.\n",
        "\n",
        "*Замечания:*\n",
        "* Все графики должны быть информативны, с подписанными осями и т.д..\n",
        "* Для чистоты эксперимента желательно не запускать в момент обучения другие задачи и провести обучение несколько раз, усреднив результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7b8654",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "dd7b8654"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "36b24378",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "36b24378"
      },
      "source": [
        "Сделайте выводы. Что будет при обучении на датасете, если  увеличить количество объектов, а число признаков оставить прежним?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7b498d1",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c7b498d1"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a8bb46",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "45a8bb46"
      },
      "source": [
        "**3.** Исследуйте влияние размер шага (`learning_rate`) на качество модели для двух режимов обучения (простой и стохастический градиентный спуск). Для каждого размера шага получите качество модели при использовании простого и стохастического градиентного спуска. Сравните качество полученных моделей по метрике `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a776cc35",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "a776cc35"
      },
      "outputs": [],
      "source": [
        "learning_rate_list = np.logspace(-5, 3, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4fe6ce",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "5a4fe6ce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0eaa44fa",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "0eaa44fa"
      },
      "source": [
        "Сделайте выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491f8d51",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "491f8d51"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58203e2",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "e58203e2"
      },
      "source": [
        "Постройте кривые обучения для различных `learning_rate`. Не обязательно рассматривать все `learning_rate`, так как их слишком много, и график будет нагроможден. Возьмите около половины из них."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85831db2",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "85831db2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fb9ae622",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "fb9ae622"
      },
      "source": [
        "Какой `learning_rate` стоит выбирать в зависимости от способа обучения модели? Чем плохи маленькие и большие `learning_rate`?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbd2848",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "fbbd2848"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05b8b99",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "a05b8b99"
      },
      "source": [
        "**4.** Рассмотрите наилучшую модель с предыдущего шага. Визуализируйте значения полученных коэффициентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5670eeec",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "5670eeec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9a9e2b5f",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "9a9e2b5f"
      },
      "source": [
        "Как можно проинтерпретировать полученные результаты относительно решаемой задачи?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55a2aea9",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "55a2aea9"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe7264e3",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "fe7264e3"
      },
      "source": [
        "**5.** Сравните данную модель с бейзлайном, который в качестве предсказания выдает самый частый класс на обучающей выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8e0954",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "9b8e0954"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "31b245e7",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "31b245e7"
      },
      "source": [
        "Насколько хорошее получилось качество обученной модели?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122f2b9c",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "122f2b9c"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32e10e7",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "e32e10e7"
      },
      "source": [
        "**Вывод:**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a14fd5",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "82a14fd5"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ba54a0",
      "metadata": {
        "copyright": "Материал разработан командой ThetaHat.",
        "id": "c3ba54a0"
      },
      "source": [
        "---\n",
        "© 2025 команда <a href=\"https://thetahat.ru/\">ThetaHat</a> для курса ML-1 ШАД"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}